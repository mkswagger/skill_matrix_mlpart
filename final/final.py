# -*- coding: utf-8 -*-
"""final.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1JciXjJCKfnDbnbMUmSHXDUBjmv4f9UUe
"""

import urllib.request

url =""
file_name = "arindam.pdf"

urllib.request.urlretrieve(url, file_name)

# !pip install pdfminer-six

from pdfminer.pdfpage import PDFPage
from pdfminer.pdfinterp import PDFResourceManager, PDFPageInterpreter
from pdfminer.converter import TextConverter
from pdfminer.layout import LAParams
import io
import os
import re



filename="arindam.pdf"
# i_f = open(filename,'rb')
# resMgr = PDFResourceManager()
# retData = io.StringIO()
# TxtConverter = TextConverter(resMgr,retData, laparams= LAParams())
# interpreter = PDFPageInterpreter(resMgr,TxtConverter)
# for page in PDFPage.get_pages(i_f):
#     interpreter.process_page(page)
#     txt = retData.getvalue()
#     print(txt)

i_f = open(filename, 'rb')
res_mgr = PDFResourceManager()
ret_data = io.StringIO()
txt_converter = TextConverter(res_mgr, ret_data, laparams=LAParams())
interpreter = PDFPageInterpreter(res_mgr, txt_converter)
for page in PDFPage.get_pages(i_f):
    interpreter.process_page(page)
    resume_text = ret_data.getvalue()
print(resume_text)
# Read the skills list from the linkedinskills.txt file
with open('linkedinskills', encoding='utf-8') as skill_file:
    skills_list = [line.strip().lower() for line in skill_file]

# Initialize an empty list to store the extracted skills
extracted_skills = []

# Loop through the skills list and look for matches in the resume text
for skill in skills_list:
    # Use regular expressions to find matches for the skill
    #p = re.compile(regexPart1 + re.escape(term) + regexPart2 , re.IGNORECASE)
    regexPart1 = r"\s"
    regexPart2 = r"(?:s|'s|!+|,|\.|;|:|\(|\)|\"|\?+)?\s"  
    pattern = re.compile(regexPart1 + re.escape(skill) + regexPart2, re.IGNORECASE)
    matches = re.findall(pattern, resume_text)
    # If matches are found, add the skill to the list
    if matches:
        extracted_skills.append(skill)

# Print the list of extracted skills
print("Extracted skills: ", extracted_skills)


# !pip install spacy

# import spacy

# # load pre-trained model
# nlp = spacy.load('en_core_web_sm')

# def extract_skill_1(resume_text):
#     nlp_text = nlp(resume_text)
#     tokens = [token.text for token in nlp_text if not token.is_stop]
    
#     # manually add skills database
#     skills = result
#     skillset = []
    
#     # one-gram skill (example: python)
#     for i in tokens:
#         if i.lower() in skills: # make every skill lowercase to match with skills database we had
#             skillset.append(i)
    
    
#     # bi-grams or tri-grams skill (example: machine learning)
#     for i in nlp_text.noun_chunks:
#         i = i.text.lower().strip()
#         if i in skills:
#             skillset.append(i)

    
#     # capitalize and remove duplicates
#     return [word.capitalize() for word in set([word.lower() for word in skillset])]


# extract_skill_1(txt)

# result = []
# with open('linkedin skill',encoding="utf-8") as f:
#     external_source = list(f)
#     for element in external_source:
#         result.append(element.strip().lower())
#     print(result)

def get_skills(document):
    skill_terms = []
    
    with open("linkedinskill", 'r',encoding="utf-8") as file:
        skill_terms = file.readlines()
    
    skill_terms = [term.strip('\n') for term in skill_terms]
    skills = []
    
    for line in document:
        words = line.split(' ')
        
        for word in words:
            if word in skill_terms:
                if word not in skills:
                    skills.append(word)
                    
        word_pairs = []
        for i in zip(words[:-1], words[1:]):
            word_pairs.append(i[0] + ' ' + i[1])   #This is to find skills like 'data science' i.e skills containint two words.    return (skills)
            
        for pair in word_pairs:
            if pair in skill_terms:
                if pair not in skills:
                    skills.append(pair)
    return (skills)
#get_skills(txt)            
#     
# import PyPDF2
# import re

# import pdfreader
# from pdfreader import PDFDocument, SimplePDFViewer
# fd = open(file_name, "rb")
# doc = PDFDocument(fd)

# def extract_skills_from_resume(file_path):
#     # Open the PDF file in read-binary mode
#     with open(file_path, 'rb') as f:
#         # Create a PDF reader object
#         pdf_reader = PyPDF2.PdfFileReader(f)
#         # Get the first page of the PDF
#         first_page = pdf_reader.getPage(0)
#         # Extract the text from the first page
#         text = first_page.extractText()
#         # Define a list of skills to look for
#         skills_list = ['Python', 'Java', 'C++', 'JavaScript', 'HTML', 'CSS', 'SQL']
#         # Initialize an empty list to store the extracted skills
#         skills = []
#         # Loop through the skills list and look for matches in the text
#         for skill in skills_list:
#             # Use regular expressions to find matches for the skill
#             pattern = re.compile(skill, re.IGNORECASE)
#             matches = re.findall(pattern, text)
#             # If matches are found, add the skill to the list
#             if matches:
#                 skills.append(skill)
#         # Return the list of extracted skills
#         return skills
# extract_skills_from_resume(filename)
